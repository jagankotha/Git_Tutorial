<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Deploying bare-metal clusters from the cloud</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/01/06/deploying-bare-metal-clusters-cloud" /><author><name>Avishay Traeger</name></author><id>e0614bca-043f-4128-8fc0-1f46d038dc96</id><updated>2022-01-06T07:00:00Z</updated><published>2022-01-06T07:00:00Z</published><summary type="html">&lt;p&gt;Our team took a fresh look at installing &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; on bare-metal hardware and developed a software-as-a-service (SaaS) installation service called the &lt;a href="https://console.redhat.com/openshift/assisted-installer/clusters/"&gt;Assisted Installer&lt;/a&gt;, available as a technology preview on the &lt;a href="https://console.redhat.com/"&gt;Red Hat Hybrid Cloud Console&lt;/a&gt;. This article describes the design and architectural choices we made in order to be able to offer the service for both on-premises and cloud deployments, while also continuously improving user experience.&lt;/p&gt; &lt;h2&gt;Installing bare-metal clusters&lt;/h2&gt; &lt;p&gt;Installing clustered software has become simpler with the adoption of virtualization and the cloud, which can provide the requisite infrastructure with a few API calls. Some software is even offered "as a service" on these platforms, allowing users to forgo installation and management.&lt;/p&gt; &lt;p&gt;However, installing bare-metal clusters is more challenging. An infrastructure administrator typically provides connected hardware, IP addresses, and other environmental configurations such as DHCP, DNS, and NTP. The cluster creator then typically configures the clustered software. In case of misconfiguration, the installation fails and the administrators must investigate the cause.&lt;/p&gt; &lt;p&gt;In designing the OpenShift Assisted Installer, our main goal was to provide an excellent user experience. This meant an intuitive and interactive flow that simplified and demystified the configuration inputs, provided early feedback, and, of course, ended with a successful installation.&lt;/p&gt; &lt;h2&gt;From the cloud to bare metal&lt;/h2&gt; &lt;p&gt;Why run the Assisted Installer service on the cloud rather than have users deploy it themselves? There are four reasons:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Users can jump into the installation process without pre-installing any software.&lt;/li&gt; &lt;li&gt;We collect aggregate metrics on usage and failures as a feedback loop for improving the service. Examples of usage information include the popularity of each feature and how many users reach each installation stage. This information helps us see where users experience difficulty with the installation. We also look at where most failures occur, and correlate failures and various parameters such as the OpenShift version or other enabled features.&lt;/li&gt; &lt;li&gt;We can easily help users debug failed installations, as all logs and events are stored by the service.&lt;/li&gt; &lt;li&gt;We deploy new versions of the Assisted Installer often in order to get the latest code into users’ hands, collect feedback quickly from metrics and failed installations, and iterate again.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;These benefits are typical for software deployed as a service. However, bare-metal hardware is not always connected to the Internet and therefore seems like a less natural fit for SaaS. Consequently, we architected the installer service to run either as a scalable SaaS or on-premises in a potentially disconnected environment. Users get all of the benefits from running as a cloud service while also offering stable versions for on-premises deployments.&lt;/p&gt; &lt;h2&gt;Assisted Installer's dual architecture&lt;/h2&gt; &lt;p&gt;Figure 1 highlights the service's deployment-specific areas. The SaaS deployment exposes a user-facing REST API and uses cloud services for storing metadata and files, as shown in red. The service is deployed on-premises as a &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Kubernetes Operator&lt;/a&gt;, exposing a Kubernetes-native &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"&gt;custom resource API&lt;/a&gt; and using locally-deployed storage, which is shown in blue. Outside of these few components, the vast majority of the service is identical in both deployment types.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Deploying%20bare-metal%20clusters%20from%20the%20cloud.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Deploying%20bare-metal%20clusters%20from%20the%20cloud.png?itok=vLlC82b9" width="600" height="475" alt="The REST API supports cloud deployments whereas Kubernetes APIs support on-premises deployments." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. The REST API supports cloud deployments whereas Kubernetes APIs support on-premises deployments. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;The first main difference between the two deployments is the user-facing API. An administrator using the SaaS would use the imperative &lt;a href="https://github.com/openshift/assisted-service/blob/master/swagger.yaml"&gt;REST API&lt;/a&gt;. For an on-premises deployment, they would use the declarative &lt;a href="https://github.com/openshift/assisted-service/tree/master/api"&gt;Kubernetes-native API&lt;/a&gt;. As is standard in Kubernetes, a &lt;a href="https://kubernetes.io/docs/concepts/architecture/controller/"&gt;controller&lt;/a&gt; implements the API logic for a resource in a “reconciliation” function that is called whenever the desired or actual state changes. Each controller compares the desired state of a resource as specified by the administrator with the resource's actual state and executes a series of imperative actions to reach the desired state. The service’s events subsystem, which allows administrators to monitor installations, also triggers the reconciliation whenever the actual state changes.&lt;/p&gt; &lt;p&gt;Before installing, the infrastructure administrator boots any number of hosts with a &lt;em&gt;discovery image&lt;/em&gt; that causes the host to run an agent process. Using the REST API, the agent registers with the installer service and polls for instructions, such as performing various validations and installing itself. The agent-service communication is well-suited for the SaaS: Because hosts are generally not publicly addressable, agents contact the service and not the other way around. We use HTTPS for added security, and the agent can be configured to use an HTTP or HTTPS proxy.&lt;/p&gt; &lt;p&gt;The installer service itself is stateless, storing its state in an SQL database and its files in an object store. This allows the SaaS deployment to scale out to handle the load from many simultaneous users. Kubernetes Operators, on the other hand, store their state in the Kubernetes cluster’s &lt;a href="https://etcd.io/"&gt;etcd&lt;/a&gt; key-value store. This currently means that we are maintaining the same state in two databases, and the Kubernetes Operator requires a persistent volume, neither of which is ideal. However, we plan to modify the service to treat the SQL database and storage as ephemeral and rely on the key-value store for the source of truth.&lt;/p&gt; &lt;p&gt;One improvement we have in mind for this architecture is to move the Kubernetes Operator into an independent component that interacts with the installer service via a REST API. The resulting operator would be more similar to existing operators interacting with external REST services, such as &lt;a href="https://github.com/crossplane/crossplane"&gt;Crossplane&lt;/a&gt; or &lt;a href="https://github.com/aws-controllers-k8s/community"&gt;ACK&lt;/a&gt;. We would first implement an efficient method for the operator to receive events via a webhook to avoid polling.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;OpenShift's Assisted Installer service illustrates how software that is traditionally on-premises and disconnected can be architected to also run as a service, providing the benefits of fast feedback-update-release cycles. This software reuse, along with a strong user-experience focus, has generated positive user feedback and a high installation success rate for this service.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/01/06/deploying-bare-metal-clusters-cloud" title="Deploying bare-metal clusters from the cloud"&gt;Deploying bare-metal clusters from the cloud&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Avishay Traeger</dc:creator><dc:date>2022-01-06T07:00:00Z</dc:date></entry><entry><title type="html">Securing LRA endpoints using JWT</title><link rel="alternate" href="https://jbossts.blogspot.com/2022/01/securing-lra-endpoints-using-jwt.html" /><author><name>Mayank Kunwar</name></author><id>https://jbossts.blogspot.com/2022/01/securing-lra-endpoints-using-jwt.html</id><updated>2022-01-05T13:26:00Z</updated><content type="html">INTRODUCTION JWT stands for JSON Web Token, which is a popular way to do user authorization in web application and is also popular in the context of micro-services. So, when we use Long Running Actions (LRA) in any micro-service, the transaction APIs could be authorized using JWT tokens. Open industry standard specification  outlines how JTW is structured and how to use it. JWT works over HTTP protocol. The reason JWT is now a days preferred more is because it makes the authorization mechanism easier for micro-service applications, avoids single point of failure and also helps the application design to be more scalable. Here is how JWT is structured: [&lt;HEADER&gt;.&lt;PAYLOAD&gt;.&lt;SIGNATURE&gt;] The JWT token is divided into three parts, as we can see in the above example which are separated by two periods.     1: HEADER -&gt; base64UrlEncode(header) 2: PAYLOAD -&gt; base64UrlEncode(payload) 3: SIGNATURE -&gt; encryptionAlgorithm(base64UrlEncode(header) + '.' + base64UrlEncode(payload),256-bit-SECRET) You can create your own JWT token by visiting website . JWT is a value token, which will only contain the user information in PAYLOAD, with the name of type of algorithm used in the HEADER and  the token verification signature in the SIGNATURE part. The above figure shows the implication of JWT. The server will create JWT token and will give it to the client, so that client can send it back on the subsequent request. Once the JWT token is created and provided to the client, we can do a REST call to  as below:  curl -H "Authorization:Bearer [&lt;HEADER&gt;.&lt;PAYLOAD&gt;.&lt;SIGNATURE&gt;]" http://127.0.0.1:8080/app/api SECURING LRA ENDPOINTS There are various LRA annotations used, which will internally call the REST APIs that are present in  and  classes. So, below are the recommendations to, how to define roles for each and every APIs in order to create JWT token for client. LRA-endPointsAllowed-roles client client client client client client client client client client system system system admin admin admin admin admin One of the popular tool that could be used to generate JWT tokens would be . Keycloak is an open source identity and access management solution. For more details about Keycloak you can also visit . PROBLEMS WITH JWT AND THEIR SOLUTIONS 1. Anyone can read first two parts of JWT tokens, i.e. HEADER and PAYLOAD, which are only base64 encoded. So, the PAYLOAD part must not contain any confidential information. It should contain enough information so that server could know who the user is. 2. If someone steals your JWT token, it will work for anyone. So in order to avoid the theft, we should be careful about how we are transmitting JWT. It has to be HTTPS connection and by using the process of  which comes with its own security and protection to make sure people don't steal JWT tokens. 3. In compare to session based authentication, if someone steals sessionID, we can log off, which ends the session and it doesn't exist anymore. But in case of JWT there is nothing on the server to end. Since the whole information is inside JWT, we only set expiration for JWT by having expiry PAYLOADs, but we cannot log off. This situation can be handled by creating blacklisted JWTs table at server side and when the request comes to server, that JWT token will be validated if not the blacklisted one then the server will authorize the request if the token had valid signature. 4. If we choose to use Expiry JWT token for LRA, then if the transaction did not complete before the token expiration, then transaction will never complete. So avoid using Expiry JWT tokens with LRA and try to follow above three ways in order to avoid the security breaches.</content><dc:creator>Mayank Kunwar</dc:creator></entry><entry><title>Extracting information from Python source code</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/01/05/extracting-information-python-source-code" /><author><name>Fridolin Pokorny</name></author><id>5a98752f-7df1-4743-ae15-2a435e6a38ab</id><updated>2022-01-05T07:00:00Z</updated><published>2022-01-05T07:00:00Z</published><summary type="html">&lt;p&gt;What library symbols does a &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; source code file use? And what symbols does it provide to its users? A simple tool called &lt;a href="https://github.com/thoth-station/invectio"&gt;invectio&lt;/a&gt; can provide this information based on static source code analysis. &lt;em&gt;Invectio&lt;/em&gt; means “import” in Latin. As the name suggests, this small tool can extract information about imports as well as information about what users can import from Python modules.&lt;/p&gt; &lt;h2&gt;Making Python symbols visible&lt;/h2&gt; &lt;p&gt;The Python standard library contains a module called &lt;a href="https://docs.python.org/3/library/ast.html"&gt;Abstract Syntax Trees&lt;/a&gt; (&lt;code&gt;ast&lt;/code&gt;), with routines to parse Python source code and access it within a program. This capability, along with other parts of the standard library, allows you to examine Python source code and extract information about symbols used or provided. Because this task is widely applicable in many situations, the &lt;a href="http://thoth-station.ninja/"&gt;Project Thoth&lt;/a&gt; team has extracted the logic into a simple application that displays the symbols used or exported by source code.&lt;/p&gt; &lt;h2&gt;invectio whatuses&lt;/h2&gt; &lt;p&gt;The first command available in &lt;code&gt;invectio&lt;/code&gt; extracts information about symbols used in the source files. Let's consider a simple &lt;a href="https://pypi.org/project/flask"&gt;Flask&lt;/a&gt; application:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;import flask app = flask.Flask(__name__) @app.route("/") def hello_world(): return flask.jsonify({})&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Running &lt;code&gt;invectio whatuses&lt;/code&gt; extracts information about symbols used from other modules, the use of built-in symbols, and Python standard library symbols. The output is in JSON format:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;$ invectio whatuses test.py { "report": { "test.py": { "__builtins__": [ "__builtins__.__name__" ], "flask": [ "flask.Flask", "flask.jsonify" ] } }, "version": "0.2.0" }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The tool can also take a directory as an argument and display the symbols from all the Python source files in that directory.&lt;/p&gt; &lt;h2&gt;invectio whatprovides&lt;/h2&gt; &lt;p&gt;Another &lt;code&gt;invectio&lt;/code&gt; subcommand extracts information about functions, classes, and constants available in the source code. Consider the following Python source code:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;CONST = 42 def is_palindrome(s: str) -&gt; bool: return s == s[::-1] # TODO: optimize&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Running &lt;code&gt;invectio whatprovides&lt;/code&gt; gives insights about symbols provided by the module:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;$ invectio whatprovides module.py { "report": { "module.py": [ "module.CONST", "module.is_palindrome" ] }, "version": "0.2.0" } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Like the &lt;code&gt;whatuses&lt;/code&gt; subcommand, the &lt;code&gt;whatprovides&lt;/code&gt; subcommand can work on directories to inspect all the Python source code present in a directory.&lt;/p&gt; &lt;h2&gt;How to install and use invectio&lt;/h2&gt; &lt;p&gt;Invectio is available as a &lt;a href="https://pypi.org/project/invectio/"&gt;Python package on PyPI&lt;/a&gt;. To install it, just enter the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ pip install invectio&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The project source files are hosted on GitHub in Project Thoth's &lt;a href="https://github.com/thoth-station/invectio"&gt;invectio repository&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;About Project Thoth&lt;/h2&gt; &lt;p&gt;This tool was developed by &lt;a href="http://thoth-station.ninja/"&gt;Project Thoth&lt;/a&gt;, part of the Artificial Intelligence Center of Excellence group (AICoE). As part of Project Thoth, we are accumulating knowledge to help Python developers create healthy applications. The introduced tool, invectio, is integrated into Thoth's client applications that aggregate information for &lt;a href="https://developers.redhat.com/articles/2021/11/17/customize-python-dependency-resolution-machine-learning"&gt;Thoth's resolver to give better guidance to developers&lt;/a&gt; on dependencies they use. If you would like to follow updates in Project Thoth, feel free to &lt;a href="https://www.youtube.com/channel/UClUIDuq_hQ6vlzmqM59B2Lw"&gt;subscribe to our YouTube channel&lt;/a&gt; or follow us on the &lt;a href="https://twitter.com/thothstation"&gt;@ThothStation Twitter handle&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/01/05/extracting-information-python-source-code" title="Extracting information from Python source code"&gt;Extracting information from Python source code&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Fridolin Pokorny</dc:creator><dc:date>2022-01-05T07:00:00Z</dc:date></entry><entry><title type="html">Orchestrate web services using RHPAM and AMQ</title><link rel="alternate" href="https://blog.kie.org/2022/01/orchestrate-web-services-using-rhpam-and-amq.html" /><author><name>Diego Torres Fuerte</name></author><id>https://blog.kie.org/2022/01/orchestrate-web-services-using-rhpam-and-amq.html</id><updated>2022-01-04T23:05:42Z</updated><content type="html">We, at the Intelligent Application Practice, recently received the request from one of our TELCO customers to provide a proof of concept about orchestrate web services using RHPAM and AMQ. Additionally, I recently came across the following post in the internet, explaining that REST is not the only way to integrate web service communication: . The previous post may give you an idea on what we are trying to accomplish here: we often think about invoking web services from our BPMN processes: Invoking an external web service from BPMN Process We have multiple ways to resolve this implementation. For example, the , that help us send a REST/HTTP request, so that we can integrate our processes with remote web services. We also have the that produces a message in a given queue name, although it seems also to default to the KIE-SERVER SIGNAL QUEUE used to complete work items. In both cases, the situation that arises is that both work item handlers act to interact with the external web service, and later complete the work item that generated the action. In our proof of concept here, we need to avoid that work item completion, so that an external entity provides in a later time, asynchronously, the completion event, along with information about the result of the remote web service execution, as in the following example: BPMN Process waiting for the remote service response Note that the process here is waiting for the external web service to integrate its response back to the BPMN process, containing the response to the inventory system on weather there was enough materials or not, so that our process can take the next gateway action appropriately, like described in the following picture: Integrate response from remote web service into BPMN Process This is accomplished with the following custom work item handler implementation: import javax.ejb.Stateless; import javax.ejb.TransactionAttribute; import javax.ejb.TransactionAttributeType; import javax.jms.Connection; import javax.jms.ConnectionFactory; import javax.jms.JMSException; import javax.jms.Message; import javax.jms.MessageProducer; import javax.jms.Queue; import javax.jms.Session; import javax.naming.InitialContext; import javax.naming.NamingException; import org.jbpm.process.workitem.core.AbstractLogOrThrowWorkItemHandler; import org.kie.api.runtime.process.WorkItem; import org.kie.api.runtime.process.WorkItemManager; import org.kie.internal.runtime.Cacheable; @Stateless public class SimpleExternalCaller extends AbstractLogOrThrowWorkItemHandler implements Cacheable { private static final int DEFAULT_PRIORITY = 5; private static final String TARGET_QUEUE = "java:/QUEUE/INBOUND"; // [1] private String connectionFactoryName = System.getProperty("org.kie.executor.jms.cf", "java:/JmsXA"); // [2] private ConnectionFactory connectionFactory; private boolean transacted = true; public SimpleExternalCaller() { super(); try { InitialContext context = new InitialContext(); if (this.connectionFactory == null) { this.connectionFactory = (ConnectionFactory) context.lookup(connectionFactoryName); } } catch (NamingException e) { // Catch action for configuration error } } @TransactionAttribute(value = TransactionAttributeType.MANDATORY) @Override public void executeWorkItem(WorkItem workItem, WorkItemManager manager) { if (connectionFactory == null) { handleException(new RuntimeException( "Failed when assigning value for AMQ connection, check the messaging configuratio")); } else { Connection queueConnection = null; Session queueSession = null; try { queueConnection = connectionFactory.createConnection(); queueSession = queueConnection.createSession(transacted, Session.AUTO_ACKNOWLEDGE); sendMessage(queueSession, TARGET_QUEUE, workItem); // [3] } catch (Exception e) { handleException(e); } finally { if (queueSession != null) { try { queueSession.close(); } catch (JMSException qce) { // catch exception while closing connection } } if (queueConnection != null) { try { queueConnection.close(); } catch (JMSException cce) { // catch exception while closing connection } } } } } private void sendMessage(Session queueSession, String queueName, WorkItem workItem) throws NamingException, JMSException { InitialContext context = new InitialContext(); Queue queue = (Queue) context.lookup(queueName); Connection queueConnection = null; MessageProducer producer = null; try { queueConnection = connectionFactory.createConnection(); queueSession = queueConnection.createSession(transacted, Session.AUTO_ACKNOWLEDGE); Message message = queueSession .createTextMessage("{'partNumber': 123, 'quantity': 300, 'assemblyLine':'abc-def'}"); String businessAutomationToken = workItem.getParameter("appName") + ":" + workItem.getProcessInstanceId() + ":" + workItem.getId(); message.setStringProperty("baToken", businessAutomationToken); // [4] producer = queueSession.createProducer(queue); queueConnection.start(); producer.setPriority(DEFAULT_PRIORITY); producer.send(message); } catch (Exception e) { handleException(e); } finally { if (producer != null) { try { producer.close(); } catch (JMSException pce) { // catch exception while closing connection to producer throw pce; } } } } @Override public void abortWorkItem(WorkItem workItem, WorkItemManager manager) { // No action to be taken during work item abort } @Override public void close() { // Nothing to release when container is removed } } IMPLEMENTATION NOTES 1. The destination queue is hard-coded to be QUEUE/INBOUND, this QUEUE needs to be part of the naming assets in the EAP web service, see the section that explains how to configure this outbound destination. 2. The connection factory name, is also part of the naming resources in the server, here we are using the same system property name that the uses to define its connection factory for the AMQ broker, if the property is not given to the system properties of the kie-server, we default that value to java:/JmsXA. See the section that explains how the remote connection is established. 3. We send the message to the defined queue, note that after this instruction, we are not “completing” the work item like other implementations, in our case, the work item creates a wait state until an external entity completes the work item using remote resources, such as the (Search for the endpoint that “Completes a specified work item”), or as we will see in the section, we use the to complete the work item through JMS. 4. The remote web service will need to know information about the work item that is generating the message, so that when in produces a response, it will be able to send the reference information back to RHPAM about the work item that RHPAM is requested to complete with certain data. We will call this reference number the “Business Automation Token”. The Business Automation Token, or B-A-Token for short, includes information about the deployment id, the process instance id, and the work item id that generated the request. See the section for information on how the remote web service generates the proper response. CONNECT RHPAM TO EXTERNAL AMQ BROKER A vital part for orchestrate web services using RHPAM and AMQ, is to make RHPAM to identify the location of the remote AMQ broker, so that it can produce messages to it, and consume messages from it. The RHPAM configuration to identify the AMQ Broker depends on the JNDI configuration for messaging subsystem in the . LOCAL SETUP For a local setup of this PoC, let’s start by Q broker: 1. Unzip the AMQ product locally. 2. Install a broker by running the command: ${ARTEMIS_HOME}/bin/activemq create broker 3. Start the broker by running the command: ${broker_home}/bin/activemq run You can also find useful information . Now, let’s install a RHPAM local instance: 1. Download and unzip EAP server to your local environment. 2. Download and unzip business-central deployable. 3. Merge the contents of business-central deployable into the EAP server directory. 4. Download and unzip kie-server deployable. 5. Place the kie-server.war in the $EAP_HOME/standalone/deployments directory, and create a file named kie-server.war.dodeploy. 6. Uncomment the sections for the controllerUser configuration at standalone-full.xml, application-roles.properties, and application-users.properties. Of course, there are , but I prefer this manual summary of actions, I feel that I have more control about what is being changed to locally install what I need. Now, here comes the Local Setup, if as a pre-requisite you already had RHPAM and AMQ broker installed, you can directly follow these steps to allow RHPAM to connect to AMQ broker: 1. In the standalone-full.xml, create an outbound-socket-binding, with a remote destination to the host and port of your amq broker: &lt;socket-binding-group name="standard-sockets" default-interface="public" port-offset="${jboss.socket.binding.port-offset:0}"&gt; &lt;socket-binding name="ajp" port="${jboss.ajp.port:8009}"/&gt; &lt;socket-binding name="http" port="${jboss.http.port:8080}"/&gt; &lt;socket-binding name="https" port="${jboss.https.port:8443}"/&gt; &lt;socket-binding name="iiop" interface="unsecure" port="3528"/&gt; &lt;socket-binding name="iiop-ssl" interface="unsecure" port="3529"/&gt; &lt;socket-binding name="management-http" interface="management" port="${jboss.management.http.port:9990}"/&gt; &lt;socket-binding name="management-https" interface="management" port="${jboss.management.https.port:9993}"/&gt; &lt;socket-binding name="txn-recovery-environment" port="4712"/&gt; &lt;socket-binding name="txn-status-manager" port="4713"/&gt; &lt;outbound-socket-binding name="mail-smtp"&gt; &lt;remote-destination host="localhost" port="25"/&gt; &lt;/outbound-socket-binding&gt; &lt;outbound-socket-binding name="messaging-remote-throughput"&gt; &lt;remote-destination host="localhost" port="61616"/&gt; &lt;/outbound-socket-binding&gt; &lt;/socket-binding-group&gt; Pay special attention to the "name", in this case to be "messaging-remote-throughput", you can assign the name you want, but you will use it in the next steps. 2. In the messaging-activemq subsystem, add a remote-connector that uses your previously created socket-binding 3. In the same messaging-activemq subsystem, add a pooled-connection-factory, that defines java:JmsXA as part of its entries, your previously created remote-connector as the connector, and the credentials to authenticate to the remote AMQ. &lt;subsystem xmlns="urn:jboss:domain:messaging-activemq:8.0"&gt; &lt;server name="default"&gt; &lt;statistics enabled="${wildfly.messaging-activemq.statistics-enabled:${wildfly.statistics-enabled:false}}"/&gt; &lt;security-setting name="#"&gt; &lt;role name="guest" send="true" consume="true" create-non-durable-queue="true" delete-non-durable-queue="true"/&gt; &lt;/security-setting&gt; &lt;address-setting name="#" dead-letter-address="jms.queue.DLQ" expiry-address="jms.queue.ExpiryQueue" max-size-bytes="10485760" page-size-bytes="2097152" message-counter-history-day-limit="10"/&gt; &lt;http-connector name="http-connector" socket-binding="http" endpoint="http-acceptor"/&gt; &lt;http-connector name="http-connector-throughput" socket-binding="http" endpoint="http-acceptor-throughput"&gt; &lt;param name="batch-delay" value="50"/&gt; &lt;/http-connector&gt; &lt;remote-connector name="netty-remote-throughput" socket-binding="messaging-remote-throughput"/&gt; &lt;in-vm-connector name="in-vm" server-id="0"&gt; &lt;param name="buffer-pooling" value="false"/&gt; &lt;/in-vm-connector&gt; &lt;http-acceptor name="http-acceptor" http-listener="default"/&gt; &lt;http-acceptor name="http-acceptor-throughput" http-listener="default"&gt; &lt;param name="batch-delay" value="50"/&gt; &lt;param name="direct-deliver" value="false"/&gt; &lt;/http-acceptor&gt; &lt;in-vm-acceptor name="in-vm" server-id="0"&gt; &lt;param name="buffer-pooling" value="false"/&gt; &lt;/in-vm-acceptor&gt; &lt;jms-queue name="ExpiryQueue" entries="java:/jms/queue/ExpiryQueue"/&gt; &lt;jms-queue name="DLQ" entries="java:/jms/queue/DLQ"/&gt; &lt;connection-factory name="InVmConnectionFactory" entries="java:/ConnectionFactory" connectors="in-vm"/&gt; &lt;connection-factory name="RemoteConnectionFactory" entries="java:jboss/exported/jms/RemoteConnectionFactory" connectors="http-connector"/&gt; &lt;pooled-connection-factory name="activemq-ra" entries="java:/JmsXALocal java:jboss/DefaultJMSConnectionFactory" connectors="in-vm" transaction="xa"/&gt; &lt;pooled-connection-factory name="activemq-ra-remote" entries="java:/JmsXA java:/RemoteJmsXA java:jboss/RemoteJmsXA" connectors="netty-remote-throughput" transaction="xa" user="admin" password="admin"/&gt; &lt;/server&gt; &lt;/subsystem&gt; Note that probably the java:/JmsXA was previously part of the activemq-ra connection factory, and we are moving that entry here to the activemq-ra-remote connection factory. 4. Set the Message Driven Bean resource adapter at the EJB3 subsystem to resolve the remote nature of our QUEUES: &lt;subsystem xmlns="urn:jboss:domain:ejb3:6.0"&gt; &lt;session-bean&gt; &lt;stateless&gt; &lt;bean-instance-pool-ref pool-name="slsb-strict-max-pool"/&gt; &lt;/stateless&gt; &lt;stateful default-access-timeout="5000" cache-ref="simple" passivation-disabled-cache-ref="simple"/&gt; &lt;singleton default-access-timeout="5000"/&gt; &lt;/session-bean&gt; &lt;mdb&gt; &lt;resource-adapter-ref resource-adapter-name="${ejb.resource-adapter-name:activemq-ra-remote.rar}"/&gt; &lt;bean-instance-pool-ref pool-name="mdb-strict-max-pool"/&gt; &lt;/mdb&gt; &lt;!-- MORE PROPERTIES REMOVED FOR BREVITY --&gt; &lt;/subsystem&gt; It appears to be a file name (activemq-ra-remote.rar), but it really is a reference to our previously created pooled-connection-factory. REGISTER DESTINATION QUEUE The QUEUEs are resolved by JNDI mechanism, so that when we call the connection factory from our InitialContext in our code, it will try to find the proper naming. Thus, we need to define how our local EAP can resolve those queue names in the remote AMQ. For this purpose, add a bindings section to the naming subsystem, as in the following snippet: &lt;subsystem xmlns="urn:jboss:domain:naming:2.0"&gt; &lt;bindings&gt; &lt;external-context name="java:global/remoteContext" module="org.apache.activemq.artemis" class="javax.naming.InitialContext"&gt; &lt;environment&gt; &lt;property name="java.naming.factory.initial" value="org.apache.activemq.artemis.jndi.ActiveMQInitialContextFactory"/&gt; &lt;property name="java.naming.provider.url" value="tcp://localhost:61616"/&gt; &lt;property name="queue.QUEUE/EXECUTOR" value="QUEUE/EXECUTOR"/&gt; &lt;property name="queue.QUEUE/RESPONSE" value="QUEUE/RESPONSE"/&gt; &lt;property name="queue.QUEUE/REQUEST" value="QUEUE/REQUEST"/&gt; &lt;property name="queue.QUEUE/SIGNAL" value="QUEUE/SIGNAL"/&gt; &lt;property name="queue.QUEUE/AUDIT" value="QUEUE/AUDIT"/&gt; &lt;property name="queue.QUEUE/INBOUND" value="QUEUE/INBOUND"/&gt; &lt;/environment&gt; &lt;/external-context&gt; &lt;lookup name="java:/QUEUE/EXECUTOR" lookup="java:global/remoteContext/QUEUE/EXECUTOR"/&gt; &lt;lookup name="java:/QUEUE/RESPONSE" lookup="java:global/remoteContext/QUEUE/RESPONSE"/&gt; &lt;lookup name="java:/QUEUE/REQUEST" lookup="java:global/remoteContext/QUEUE/REQUEST"/&gt; &lt;lookup name="java:/QUEUE/SIGNAL" lookup="java:global/remoteContext/QUEUE/SIGNAL"/&gt; &lt;lookup name="java:/QUEUE/AUDIT" lookup="java:global/remoteContext/QUEUE/AUDIT"/&gt; &lt;lookup name="java:/QUEUE/INBOUND" lookup="java:global/remoteContext/QUEUE/INBOUND"/&gt; &lt;/bindings&gt; &lt;remote-naming/&gt; &lt;/subsystem&gt; Note here that we are binding the 5 QUEUES that RHPAM would probably use for its functions, as well as the QUEUE that we will use for the remote system communication (QUEUE/INBOUND). Find the end result standalone-full.xml . ENABLING SIGNAL JMS Message listeners in EAP are performed with (MDB). It is important for you to know that nothing prevents you from developing your own MDB, and deploy that MDB to the execution context of the EAP server to start reading messages from those queues, or more if you want. Then, using the service discovery from the EAP server, discover the RHPAM runtime engine and do whatever you want with your kjar, assets, and instances. By knowing that information, the sky is the limit and you will have all the power to customize the KIE-SERVER listeners to your liking. But let’s get this simpler, RHPAM already has pre-defined MDBs that are listening to messages, in our case, we will leverage the existence of the to help us complete our work item when a message is received at the QUEUE/SIGNAL queue. To enable the MDB, you need to modify the kie-server.war’s ejb-jar.xml file (find this file at $EAP_HOME/standalone/deployments/kie-server.war/WEB-INF/ejb-jar.xml), in the ejb-jar.xml you need to make sure that the JMSSignalReceiver bean is not commented out, and you can also include the QUEUE name that it is listening to: &lt;message-driven&gt; &lt;ejb-name&gt;JMSSignalReceiver&lt;/ejb-name&gt; &lt;ejb-class&gt;org.jbpm.process.workitem.jms.JMSSignalReceiver&lt;/ejb-class&gt; &lt;transaction-type&gt;Bean&lt;/transaction-type&gt; &lt;activation-config&gt; &lt;activation-config-property&gt; &lt;activation-config-property-name&gt;destinationType&lt;/activation-config-property-name&gt; &lt;activation-config-property-value&gt;javax.jms.Queue&lt;/activation-config-property-value&gt; &lt;/activation-config-property&gt; &lt;activation-config-property&gt; &lt;activation-config-property-name&gt;destination&lt;/activation-config-property-name&gt; &lt;activation-config-property-value&gt;java:/QUEUE/SIGNAL&lt;/activation-config-property-value&gt; &lt;/activation-config-property&gt; &lt;/activation-config&gt; &lt;/message-driven&gt; For the sake of completion, and preparing for multi-tenant situations, in the we are also enabling the MDBs for the EXECUTOR, and KIE-SERVER, these listeners would enable additional interactions of kie-servers with the AMQ broker. REPLYING TO RHPAM If you reach this point, start your AMQ Broker, deploy a kjar that uses the work item handler to your running kie-server, and start a process instance, you will reach the point where the process produces a message in the INBOUND queue. At last we need an application now, known as the remote web service, that reads the message from the INBOUND queue, performs some logic, and replies to RHPAM with the result of its operation. A simple class that performs these sort of operations in spring-boot looks like this: import static org.kie.server.api.jms.JMSConstants.CONTAINER_ID_PROPERTY_NAME; import java.io.ByteArrayOutputStream; import java.io.IOException; import java.io.ObjectOutputStream; import java.util.HashMap; import java.util.Map; import javax.jms.BytesMessage; import javax.jms.JMSException; import javax.jms.Message; import javax.jms.Session; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.jms.annotation.JmsListener; import org.springframework.jms.core.JmsTemplate; import org.springframework.jms.core.MessageCreator; import org.springframework.messaging.MessageHeaders; import org.springframework.stereotype.Component; @Component public class QueueAReceiver { private static final Logger logger = LoggerFactory.getLogger(QueueAReceiver.class); private static final String REQUEST_QUEUE = "QUEUE/SIGNAL"; @Autowired private JmsTemplate jmsTemplate; @JmsListener(destination = "QUEUE/INBOUND", containerFactory = "remoteConnectionFactory") public void receiveMessage(String partsProcurementJson, MessageHeaders messageHeaders) { String baToken = (String) messageHeaders.getOrDefault("baToken", "UNKNOWN"); logger.info("Received message for baToken: {}", baToken); logger.info("Received message &lt;{}&gt;", partsProcurementJson); logger.debug("Producing a message for RHPAM to continue operation with baToken {}", baToken); String[] tokenParts = baToken.split(":"); String deploymentId = tokenParts[0]; Long processInstanceId = Long.parseLong(tokenParts[1]); Long workItemId = Long.parseLong(tokenParts[2]); Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put("partsAvailable", Boolean.TRUE); jmsTemplate.send(REQUEST_QUEUE, new MessageCreator() { @Override public Message createMessage(Session session) throws JMSException { BytesMessage message = session.createBytesMessage(); // TODO: this correlation key works better if it is unique, it helps correlate // responses in the RESPONSE QUEUE, with requests in the SIGNAL QUEUE. message.setJMSCorrelationID(baToken); message.setStringProperty(CONTAINER_ID_PROPERTY_NAME, deploymentId); message.setObjectProperty("KIE_DeploymentId", deploymentId); message.setObjectProperty("KIE_SignalWorkItemId", workItemId); message.setObjectProperty("KIE_SignalProcessInstanceId", processInstanceId); try { message.writeBytes(convertToBytes(params)); } catch (IOException e) { logger.error("Unable to serialize parameters to bytes", e); } return message; } }); } private byte[] convertToBytes(Object object) throws IOException { try (ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream out = new ObjectOutputStream(bos)) { out.writeObject(object); return bos.toByteArray(); } } } Find more information about consuming and producing messages in AMQ . Note in our code that we are using some coupling requirements from the so that it can understand our reply: 1. The CONTAINER_ID_PROPERTY_NAME is a constant defined in the kie-server api library, but the other strings required by the receiver are not, so that they are required to find the work item to complete. 2. The message is a byte message with the serialized representation of the Map&lt;String, Object&gt; with the parameters to send to the signal. If you happen to send a custom object in one of those entries, it better implements the Serializable interface, or you will lose its value. DEMO Here I leave you as last part of my post a demo of the previously configured instance, I am planning to later work with one of my team mates to publish an Openshift implementation, and to implement some more elegant pattern of integration, such as the SAGA pattern using these tools. Thanks for reading this far, now go and automate the world. The post appeared first on .</content><dc:creator>Diego Torres Fuerte</dc:creator></entry><entry><title type="html">Getting started with Netty</title><link rel="alternate" href="http://www.mastertheboss.com/jboss-frameworks/netty/jboss-netty-tutorial/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=jboss-netty-tutorial" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/jboss-frameworks/netty/jboss-netty-tutorial/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=jboss-netty-tutorial</id><updated>2022-01-01T03:35:00Z</updated><content type="html">Netty is a client/server framework that provides a simplified layer over NIO networking. This makes it a good candidate to create low-level nonblocking network applications. Overview of Netty Before we begin with a practical example, let’s see the main highlights of Netty framework: Ease of use: Netty is simpler to use than plain Java NIO ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">2021 year in review - The new normal?</title><link rel="alternate" href="http://www.schabell.org/2021/12/2021-year-in-review.html" /><author><name>Eric D. Schabell</name></author><id>http://www.schabell.org/2021/12/2021-year-in-review.html</id><updated>2021-12-31T06:00:00Z</updated><content type="html">The year 2021 is coming to a close, ending pretty much the same way here in the Netherlands as it started in 2020... a lockdown. Empty streets, closed shops, closed restaurants, no parties, no gatherings, and all just when we thought it might be getting back to normal. Not yet. Meanwhile work has gone one and life has continued for me with little change other than the occasional possibility to get out and about to visit you. Just like in 2020, we've shared more time together this year online in virtual events, coffee breaks, and other strange virtual events. On the up side there were the possibilities to travel again in 2021 and I got to spend time with my family back in the US for the first time in over three years! This year I spent all my time generating architecture content, upgrading demos, updating workshops, and spreading as much good cheer as I could from behind my webcam. I was able to visit a few customers in the Netherlands and even get out and about for an overseas event in Ireland, but I'll get to that in a bit. It was my +12th year at Red Hat and the worldwide pandemic continued to influence our daily lives as it surged and subsided throughout the year. While it's a constant in all the planning and activities, let's review some of the activities from 2021 that were not affected by the pandemic. PUBLISHING Again this year I've been publishing a lot online, maybe even more so now that the events are all virtual  and I needed to float new ideas for your review. This year I've published  on this site, many were , and multiple articles featured elsewhere on external sites.  I also did a few special writing projects, such as the . My hobby of writing as  continued, but slowed considerably due to the shortened season and my time being used up elsewhere. It's been amazing to share these insights and experiences that can make others better at what they do. It's the most rewarding part of working in open source, the sharing, mentoring, and collaboration that makes all around you grow. Speaking engagements were numerous, but mostly virtual until the in person event in Ireland (see travel below). One of the more fun ones was a workshop I delivered during my vacation from a hotel on an island in Greece, always a challenge! There were too many speaking engagements to list here so just sending you over to my for the listing and content made available from my sessions there. Here are some of the feedback that was shared throughout the year: “Was in a class last week, about becoming a manager. And they asked a question about who inspire you the most as a leader, guess who came to my mind first &#x1f61b;. You &#x1f600;. I think a true leader leads by example. And just want you should know how much you inspired me.” “Pleasure having you around. A good man with a good heart.” “Thanks Eric, you are an amazing person and someone I always enjoyed working with." “Many thanks for all your help Eric and for all the top material you create, it is absolutely helpful and a big asset to spread the word of what we at Red Hat can do. Really enjoy working with you, man!” “Do we have a UI for Eric's brain? Like, I can just type in a TLA and get a printout?” “DZone Community Member of the Day: Eric D. Schabell. Long-time DZone contributor he’s  posted over 300 articles on DZone that have generated over 2.1 million page views.” “Well done Eric! Amazing to see how much you have contributed back to the community by sharing your knowledge”  “Such a fun session! Took a ton of notes to better understand the environment and opportunities available for hybrid cloud and digital transformation. Should take the band on the road guys!”“Well done Eric! Amazing to see how much you have contributed back to the community by sharing your knowledge”  “Thanks Eric, this is really useful to learn the main features of PAM.!”  “You’re leaders in this space (Portfolio Architecture), this is just awesome content!” CODING AND OTHER CONTENT This year saw the  complete its sixth year since the first commit on April 1, 2016 and is hosted on Gitlab. This year it continued to expand beyond the projects illustrating containers, cloud operations, deployments, AppDev in the Cloud to include more portfolio architecture workshops and example repositories. Be sure to jump on over there and watch the updates as container based projects are migrating to OpenShift Container Platform 4.x and beyond. Almost all of my workshops and demo projects have been updated and are based on installing using OpenShift through the CodeReady Containers offering or just native containers with : * : * * * * * : * * * These workshops are all constantly undergoing revisions and updates to add new product innovations so be sure to check them out thorough next year. The biggest work I've delivered on this year can be found in the  repository where I've added 12 new architecture projects ranging from cloud adoption, remote server management, retail, and healthcare projects. This is just the public facing content, there is more but that's targeting enablement of the internal field teams at Red Hat. TRAVEL This year the travel was a bit better than 2020, but not by much. Several lockdowns hampered travel for most of us, but here's the overview. Just for reference, back in 2019 a normal travel year was over 138,000 km, 22 cities, and 9 countries. In 2021 it was just five trips covering 22,914km, 8 cities, and 4 countries.  Four of those trips were personal vacations, so only one trip was made for work:  * Dublin, Ireland (work) One can only hope we are meeting even more face to face soon in 2022 and I'm seeding conferences with sessions throughout the coming year to be ready when it happens. TIME FOR OTHER PROJECTS The positive side of this lack of travel is that I've worked on a lot of physical projects around my home again in 2021. I'm a type of person that likes to fix stuff that breaks down himself, so I have turned my attentions to maintenance and improvements for my home along with some professional builders for the bigger projects: * painted three more interior doors and all their door frames * remodelled two bathrooms * remodelled fireplace * replaced four external windows and repainted frames * started playing with mobile development around react-native As long as the travel is not taking up all my time I'll plan to continue with the maintenance work in 2022. THANKS TO YOU ALL Here is hoping you enjoyed what I was able to bring to you in 2021. I'm sharing, entertaining, and hopefully slipping in a bit of educational content for your daily lives. I want to thank you personally for attending any of the webinars, virtual conference sessions, online workshops, and for taking the time to read my published articles. As 2022 kicks off, there's hope for travel and in person events, but using the mediums we have at our disposal we'll continue to explore the amazing things you can achieve with open technologies. Finally, stay safe, take care of yours, and hope to see you soon face to face!</content><dc:creator>Eric D. Schabell</dc:creator></entry><entry><title>Top 10: Our most read developer articles of 2021</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/12/27/top-10-our-most-read-developer-articles-2021" /><author><name>Red Hat Developer Editorial Team</name></author><id>70db31e2-087e-4351-b257-36597cc455fc</id><updated>2021-12-27T07:00:00Z</updated><published>2021-12-27T07:00:00Z</published><summary type="html">&lt;p&gt;We're taking a quick break from the winter recharge to share our 10 most read articles of 2021. Some of the best developers in the world work for Red Hat, and we're fortunate that many of them contribute to Red Hat Developer. We think this year's top 10 articles showcase the breadth of our contributors' interests and expertise, as well as that of our readers. Without further ado, here are Red Hat Developer's most popular articles of 2021.&lt;/p&gt; &lt;h2&gt;1. How to activate your no-cost Red Hat Enterprise Linux subscription&lt;/h2&gt; &lt;p&gt;Following the January 2020 announcement of Red Hat's new &lt;a href="https://developers.redhat.com/products/rhel/download"&gt;no-cost Red Hat Enterprise Linux (RHEL) subscription&lt;/a&gt;, this article walks you through everything you need to set up a subscription in three easy steps. No wonder &lt;a href="https://developers.redhat.com/author/miroslav-suchy"&gt;Miroslav Suchý&lt;/a&gt;'s &lt;a href="https://developers.redhat.com/blog/2021/02/10/how-to-activate-your-no-cost-red-hat-enterprise-linux-subscription"&gt;How to activate your no-cost Red Hat Enterprise Linux subscription&lt;/a&gt; was our most-read article in 2021!&lt;/p&gt; &lt;h2&gt;2. Distributed transaction patterns for microservices compared&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/authors/bilgin-ibryam"&gt;Bilgin Ibryam&lt;/a&gt; is co-author of the &lt;a href="https://developers.redhat.com/books/kubernetes-patterns"&gt;Kubernetes Patterns&lt;/a&gt; e-book and a frequent contributor, with over a dozen articles published on Red Hat Developer to date. In &lt;a href="https://developers.redhat.com/articles/2021/09/21/distributed-transaction-patterns-microservices-compared"&gt;Distributed transaction patterns for microservices compared&lt;/a&gt;, he discusses the benefits and drawbacks of five distributed transaction patterns and addresses one of the pain points of modernizing monolithic applications into &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt;. We expect readers will seek out this article for years to come.&lt;/p&gt; &lt;h2&gt;3. Application modernization patterns with Apache Kafka, Debezium, and Kubernetes&lt;/h2&gt; &lt;p&gt;Another article in Bilgin's series tackling the challenges of modernizing legacy applications, this one offers both a well-tested pattern (Strangler, used in tandem with Outbox, Sidecar, and Saga) and standardized tools for implementing it. &lt;a href="https://developers.redhat.com/articles/2021/06/14/application-modernization-patterns-apache-kafka-debezium-and-kubernetes"&gt;Application modernization patterns with Apache Kafka, Debezium, and Kubernetes&lt;/a&gt; is a must-read for developers interested in using &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Apache Kafka&lt;/a&gt; to create robust systems that evolve over time.&lt;/p&gt; &lt;h2&gt;4. Making environment variables accessible in front-end containers&lt;/h2&gt; &lt;p&gt;We published many articles in 2021 about developing and deploying applications in &lt;a href="https://developers.redhat.com/topics/containers"&gt;containers&lt;/a&gt;, but this one stood out for its focus on building containers for single-page &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; applications. As author &lt;a href="https://developers.redhat.com/authors/joel-lord"&gt;Joel Lord&lt;/a&gt; explains, the application's configuration settings will be different depending on where the container runs, and the challenge is how to make those settings accessible in any environment. &lt;a href="https://developers.redhat.com/blog/2021/03/04/making-environment-variables-accessible-in-front-end-containers"&gt;Making environment variables accessible in front-end containers&lt;/a&gt; leaves you with a solution that you can reuse for any of your future JavaScript projects.&lt;/p&gt; &lt;h2&gt;5. C# 9 top-level programs and target-typed expressions&lt;/h2&gt; &lt;p&gt;Red Hatter and .NET Core developer &lt;a href="https://developers.redhat.com/author/tom-deseyn"&gt;Tom Deseyn&lt;/a&gt;'s C# 9 language features series was our most popular series this year. This article, &lt;a href="https://developers.redhat.com/blog/2021/03/30/c-9-top-level-programs-and-target-typed-expressions"&gt;C# 9 top-level programs and target-typed expressions&lt;/a&gt;, started it all.&lt;/p&gt; &lt;h2&gt;6. C# 9 pattern matching&lt;/h2&gt; &lt;p&gt;The second article in the C# 9 series, &lt;a href="https://developers.redhat.com/blog/2021/04/06/c-9-pattern-matching"&gt;C# 9 pattern matching&lt;/a&gt; introduces changes to pattern matching in C# 9, including updates and support for combining, inverting, and nesting patterns. A breezy read with many code samples for developers adopting C# 9.&lt;/p&gt; &lt;h2&gt;7. Why should I choose Quarkus over Spring for my microservices?&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/quarkus"&gt;Quarkus&lt;/a&gt; is one of our most popular topics on Red Hat Developer, and &lt;a href="https://developers.redhat.com/articles/2021/08/31/why-should-i-choose-quarkus-over-spring-my-microservices"&gt;this article&lt;/a&gt; by Quarkus and Spring Boot developer &lt;a href="https://developers.redhat.com/author/eric-deandrea"&gt;Eric Deandrea&lt;/a&gt; helps to explain why. Find out why many Spring developers are switching to Quarkus and how to get started using the Kubernetes-native Java platform for your microservices.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you're ready to make the leap from Spring to Quarkus, see Eric's e-book, &lt;a href="https://developers.redhat.com/e-books/quarkus-spring-developers"&gt;Quarkus for Spring Developers&lt;/a&gt;, published by Red Hat Developer in August 2021.&lt;/p&gt; &lt;h2&gt;8. Shenandoah in OpenJDK 17: Sub-millisecond GC pauses&lt;/h2&gt; &lt;p&gt;The Shenandoah OpenJDK garbage collection project was created to reduce garbage collection pause times, and &lt;a href="https://developers.redhat.com/articles/2021/09/16/shenandoah-openjdk-17-sub-millisecond-gc-pauses"&gt;this article&lt;/a&gt; concludes a series explaining how the Shenandoah team did it. Shenandoah GC Project Lead &lt;a href="https://developers.redhat.com/author/roman-kennke"&gt;Roman Kennke&lt;/a&gt; opens with a retrospective of pause time improvements from JDK 12 through 16, then describes how introducing concurrent thread stack processing solved the remaining garbage collection pause-time challenge in JDK 17.&lt;/p&gt; &lt;h2&gt;9. Deploy Helm charts with Jenkins CI/CD in Red Hat OpenShift 4&lt;/h2&gt; &lt;p&gt;This &lt;a href="https://developers.redhat.com/articles/2021/05/24/deploy-helm-charts-jenkins-cicd-red-hat-openshift-4"&gt;quick read&lt;/a&gt; by &lt;a href="https://developers.redhat.com/author/shailendra-kumar-singh"&gt;Shailendra Kumar Singh&lt;/a&gt; gets you started with Helm and Jenkins CI/CD in a step-by-step tutorial. Start with an overview of the Helm package manager for Kubernetes, then create and deploy your first Helm chart and use it to deploy an application using Jenkins CI/CD and &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift.&lt;/a&gt; A simple, practical introduction written for beginners.&lt;/p&gt; &lt;h2&gt;10. How to work around Docker's new download rate limit on OpenShift&lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2021/02/18/how-to-work-around-dockers-new-download-rate-limit-on-red-hat-openshift"&gt;This article&lt;/a&gt;, a response to Docker's new download rate limits for anonymous users, introduced in November 2020, explains how to get around the unwanted &lt;code&gt;toomanyrequests&lt;/code&gt; error without upgrading to a paid Docker account. Note that this hack, presented by &lt;a href="https://developers.redhat.com/authors/joel-lord"&gt;Joel Lord&lt;/a&gt;, is specifically for developers experimenting with a free OpenShift cluster in the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;We hope you've enjoyed this recap of Red Hat Developer's 10 most read articles and tutorials published in 2021. During the past year, we've had the pleasure of publishing hundreds of technical articles and other resources (such as &lt;a href="https://developers.redhat.com/cheat-sheets"&gt;cheat sheets&lt;/a&gt;, &lt;a href="https://developers.redhat.com/learn"&gt;interactive courses&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/developer-sandbox/get-started"&gt;Developer Sandbox activities&lt;/a&gt;) written by developers working at Red Hat. See the following for more of our most sought articles and other resources in 2021:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/12/01/kubernetes-and-openshift-best-2021"&gt;The best of Kubernetes and OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/12/08/red-hat-enterprise-linux-best-2021"&gt;The best of Red Hat Enterprise Linux&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/12/15/ansible-and-automation-best-2021"&gt;The best of Ansible and automation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/12/22/java-quarkus-kafka-and-more-best-2021"&gt;The best of Java, Quarkus, Kafka, and more&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Happy New Year from all of us on the Red Hat Developer editorial team!&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/12/27/top-10-our-most-read-developer-articles-2021" title="Top 10: Our most read developer articles of 2021"&gt;Top 10: Our most read developer articles of 2021&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Red Hat Developer Editorial Team</dc:creator><dc:date>2021-12-27T07:00:00Z</dc:date></entry><entry><title type="html">Installing Fedora 35 on Macbook Pro 13 inch (late 2011)</title><link rel="alternate" href="http://www.schabell.org/2021/12/installing-fedora-35-on-macbook-pro-13-inch-late-2011.html" /><author><name>Eric D. Schabell</name></author><id>http://www.schabell.org/2021/12/installing-fedora-35-on-macbook-pro-13-inch-late-2011.html</id><updated>2021-12-27T06:00:00Z</updated><content type="html">This weekend I decided to update my old Macbook Pro 13 inch from late 2011, with 125GB SSD and 8GB RAM. It's a machine I've taken on trips around the world and back in the day ran many a session, workshop, or demo on sharing all that AppDev goodness you know from JBoss technologies. Last time we checked, this was , so how about an update to Fedora 35? Below the steps and adjustments needed to  working on this laptops in under an hour. GET FEDORA 35 The first step is to find the right way to install Fedora on this laptop. It does have a CD slot so I guess one could opt for burning an ISO to boot from, but I chose to go straight to a bootable USB option. I got on my other Macbook and visited the  where you find a link to Fedora Media Writer. Just click on the icon (in my case, the apple) for your machine type and you get an installation package.  Install this and start it to see the GUI that guides you through the process. Select the Fedora Workstation 35 option: Next you can select the top right button to Create Live USB option: Then you'll see the image start to download and the drop down menu for selecting where to install the image. If you now plug in an USB stick with the right size available, you can select and install the image directly onto the USB device: Once finished just close this GUI and remove the USB stick.  INSTALLING ON MACBOOK PRO 13 INCH (LATE 2014) Insert the USB stick you created above, there is a port on the left side for this, (re-)start your Macbook Pro and be sure to hold down the Option (or alt) key, just to the left of the CMD key. This opens a menu of options to start this machine from and we'll need to use the EFI option as that's our USB image. Now it's booting from the device and you just can follow the . It really helps if you have a network cable connection you can plug your Macbook Pro into as the wifi device (broadcom) does not work out of the box.  You should get the chance to install to hard drive and put it on your machine permanently. Once you've completed the installer, reboot your machine and you should see Fedora 33 as the option to boot from and end up in your new machine. Now the only thing missing is a wifi driver so there are a few things to be done that require that network cable to be connected as we install the development packages for the kernel we are running and then build the broadcom-wl driver for that kernel. Let's verify the actual card we need for wifi in a terminal: $ lspci -vnn -d 14e4: The output will be several items, one of which should be listing something like: Network controller [0280]: Broadcom Inc. and subsidiaries.... Subsystem: Apple Inc. AirPort Extreme... We now need to install a repository to pull the broadcom stuff as follows: $ su -c 'dnf install -y http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm' And then the non-free repository: $ su -c 'dnf install -y http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm' The next part is interesting as you look at the running kernel you'll see v5.15.11-200.fc35 but we are going to be using the development kernel packages to build our broadcom wireless driver so you need to install the v5.14.10-300.fc35 (available at the time of this writing). You can check these using 'uname -r' and list the installed kernel packages using 'sudo dnf list kernel': $ sudo dnf list kernel kernel.x86_64                     5.14.10-300.fc35 kernel.x86_64                     5.15.11-200.fc35 Install the development packages with the following: $ sudo dnf install -y akmods kernel-devel-5.14.10-300.fc35 You'll see a lot of packages scroll by and then the development kernel package install: Now install the Broadcom Wireless package: $ sudo dnf install -y broadcom-wl Now build the kernel module: $ sudo akmods Checking mods exist for 5.15.11-200.fc35.x86_64     [OK] Now reboot your machine and you should be able to view the wireless driver (wl) with the following: $ lsmod | grep wl Now setup your wireless connection in Fedora: Pretty straight forward if you were following along the last time, so hope you enjoyed this end of the year update to the latest Fedora on your old Macbook Pro 13 inch from late 2011! &gt; Starting to look at upgrading my macbook from 2011 by installing 35 on it. &gt; Crossing fingers that the wifi card works without manual intervention. Will be &gt; reporting back soon with the results. Here's the overview of the steps from &gt; last time: &gt; &gt; — Eric D. Schabell (@ericschabell)</content><dc:creator>Eric D. Schabell</dc:creator></entry><entry><title>Quarkus 2.6.1.Final released - Maintenance release</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-2-6-1-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-2-6-1-final-released/</id><updated>2021-12-24T00:00:00Z</updated><published>2021-12-24T00:00:00Z</published><summary type="html">2021 has been a tremendous year for Quarkus and today we officially close our 2021 release season with the last maintenance release of the year: 2.6.1.Final is available on Maven Central and ready for consumption! It is a safe upgrade for anyone already using 2.6 and contains dozens of small...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2021-12-24T00:00:00Z</dc:date></entry><entry><title type="html">Infinispan and Log4j CVE-2021-45046 CVE-2021-45105</title><link rel="alternate" href="https://infinispan.org/blog/2021/12/23/infinispan-log4j-cve-releases" /><author><name>Ryan Emerson</name></author><id>https://infinispan.org/blog/2021/12/23/infinispan-log4j-cve-releases</id><updated>2021-12-23T12:00:00Z</updated><content type="html">Dear Infinispan community, We’ve just released , and to address the latest CVEs that affect log4j-core (, ). Additionally, we have released upgraded versions of the Infinispan Operator to match the server versions: 2.2.3.Final for Infinispan 13.0 and 2.1.7.Final for Infinispan 12.1. Please upgrade as soon as you can. Refer to our for versions. WHAT’S AFFECTED We include log4j-core in our server distributions, including the . We are fixing the issue by upgrading to Log4J 2.17.0. MITIGATION STRATEGIES If you cannot upgrade, there are a several you can apply. But upgrading is always the best solution.</content><dc:creator>Ryan Emerson</dc:creator></entry></feed>
